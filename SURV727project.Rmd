---
output:
  word_document: default
  html_document: default
  pdf_document: default
---
# SURV727-Project
---
title: "Sentiment Analysis of Tweets on Georgia Abortion Law"
subtitle: "SURV727 Term Paper"
author: "Akipu Ehoche and Ellena Sempeles"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    df_print: kable
 references:
- id: Blazina2022
  title: Key facts about the abortion debate in America
  author:
  - family: Blazina
    given: C.
  container-title: Pew Research
  type: article-online
  issued:
    year: 2022
- id: BellwareRoubein2022
  title: Judge overturns Georgia’s six-week abortion ban
  author:
  - family: Bellware
    given: K.
  - family: Roubein
    given: R.
  type: article-online
  container-title: The Washington Post
  issued:
    year: 2022
- id: Thanawala2022
  title: Georgia Supreme Court reinstates ban on abortions after 6 weeks of pregnancy
  author:
  - family: Thanawala
    given: S.
  type: article-online
  container-title: PBS
  issued:
    year: 2022
---

```{r, include = FALSE}
library(knitr)
library(tidyverse)
library(rtweet)
library(tidytext)
library(qdap)
```
## Introduction
In June of 2022, the Supreme Court issued its decision in Dobbs vs. Jackson Women’s Health, overturning Roe vs. Wade, eliminating the federal standard protecting the right to abortion. This sparked a major political and morality debate across the American population, where opinions and comments were shared via various social media platforms, including Twitter. According to a survey of U.S. adults conducted by Pew Research Center in the summer of 2022, a majority of the U.S. public disapproves of the Supreme Court's decision. Roughly 57% of adults dissaprove of the court's decision, including 43% who strongly disapprove, while 41% approve, including 25% who strongly approve [@Blazina2022].The state of Georgia’s abortion law was among of the strictest in the country, banning abortion after the detection of fetal cardiac activity, at roughly six weeks. However, as of November 15th, 2022, a breaking news story reported that a Fulton County judge overturned Georgia’s six-week abortion ban [@BellwareRoubein2022]. Then, as of November 23rd, 2022, the state attorney general's office appealed the ruling to the state Supreme Court, allowing the six-week abortion ban to take effect once again [@Thanawala2022]. Given the country's divide on the issue of abortion and the back and forth of Georgia's legislation, we are interested in the emotional reactions of Twitter users' tweets on these changes of legislation, as well as, the mapping of this topic of conversation across the country. Our questions include:
1) What are people saying about the changes in Georgia’s abortion law? 
2) Are their reactions positive or negative?
3) Where in the country are people talking about this? 

This paper provides a sentiment analysis of Twitter users' tweets on the topic of abortion in the state of Georgia.

## Data
Two corpuses of tweets were collected to examine the sentiment of Twitter users regarding the Georgia abortion ban. Using the Twitter API, a total of xxx tweets were collected over two periods of time, after the abortion ban was overturned and after it was reinstated. The first corpus was collected for a span of 12 hours starting at 10:00PM EST on November 15, 2022. Given that the abortion ban was overturning on that specific day, this corpus of tweets captured Twitter users' inital reaction to the the overturning. The second corpus was collected for a span of 12 hours starting at 5:00PM EST on November 23, 2022. This corpus of tweets captured Twitter users reactions after the news of the ban reinstatement. This second batch of tweets were collected in three installments.


```{r, eval=FALSE }
# A code chunk that exemplifies the data gathering process
ban_tweets <- stream_tweets(
  q = "georgia ban abortion",
  timeout = 15600,
  file_name = "tweet1",
  parse = FALSE
)
ban_tweets <- stream_tweets(
  q = "georgia ban abortion",
  timeout = 1800,
  file_name = "tweet2",
  parse = FALSE
)
ban_tweets <- stream_tweets(
  q = "georgia ban abortion",
  timeout = 43200,
  file_name = "tweet3",
  parse = FALSE
)
ban_tweets <- stream_tweets(
  q = "georgia ban abortion",
  timeout = 15600,
  file_name = "tweet4",
  parse = FALSE
)

#add second stream here, please change names of objects:
ban_tweets2 <- stream_tweets(
   q = "georgia ban abortion",
  timeout = 86400,
  file_name = "tweet2",
  parse = FALSE
) 

```



How much tweets were collected?
```{r }
keywords <- parse_stream("tweet1")
keywords1 <- keywords
ts_plot(keywords, by = "secs")
```

The corpuses were then cleaned for later text analysis. This cleaning procedures included
-removing stopwords
-removing website tags?
-are we doing stemming and lemmatization?

```{r, include=TRUE}
keywords$text <- gsub("http.*", "", keywords$text)
keywords$text <- gsub("https.*", "", keywords$text)
keywords$text <- gsub("&amp;", "&", keywords$text)

keywords_clean <- keywords %>%
  select(text) %>%
  unnest_tokens(word, text)

nrow(keywords_clean)

stopwds <- get_stopwords("en")
keywords_cleaner <- keywords_clean %>%
  anti_join(stopwds)

nrow(keywords_cleaner)


plot1 <- keywords_cleaner %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() +
  geom_col(aes(x = word, y = n)) +
  coord_flip() 
plot1
#This is different code to remove stop words (from Twitter API): so far it is leaving entire sentences, need another look
#bagVaccines = keywords1$text %>% iconv("latin1", "ASCII", sub="") %>% scrubber() %sw% qdapDictionaries::Top200Words
#nrow(bagVaccines)
#df <- as.data.frame(bagVaccines)
#nrow(df$bagVaccines)
#df %>%
  #count(bagVaccines, sort = TRUE) %>%
  #top_n(15) %>%
  #mutate(word = reorder(bagVaccines, n)) %>%
  #ggplot() +
  #geom_col(aes(x = bagVaccines, y = n)) +
  #coord_flip() -> Method2
#Method2

```

Using stemming to clean up the data, we get
```{r, include=TRUE}
library(quanteda)
library(lexicon)

keywords_clean1 <- as.data.frame(keywords_clean)
toks <-  corpus(keywords_clean1$word) %>%
  tokens(remove_punct = TRUE, remove_numbers = FALSE, remove_symbols = TRUE) %>% 
  tokens_wordstem()

toks1 <- data.frame(text = sapply(toks, as.character), stringsAsFactors = FALSE)
plot2 <- toks1 %>%  mutate(word=text) %>%
  anti_join(stopwds) %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() +
  geom_col(aes(x = word, y = n)) +
  coord_flip()
plot2
```

Comparing the two plots using the different cleaning methods side by side
```{r, include=TRUE}
require(patchwork)
library(patchwork)
plot1 + plot2
```

Plot 1 represents cleaning up the data as described above while plot2 has formatted the words after the cleaning using stemming.
```{r}
# Mapping Tweets
library(maps)
## create lat/lng variables using all available tweet and profile geo-location data
us = lat_lng(keywords)
## plot state boundaries
par(mar = c(0, 0, 0, 0))
maps::map("state", lwd = .25)
## plot lat and lng points onto state map
points(us$lng, us$lat, pch = 20, cex = .75, col = rgb(0, .3, .7, .75))
```
Most of the location data is missing, so the map is sparsely populated



```{r}
# Filtering irrelevant tweets?

```

```{r, echo=FALSE}
#Sentiment Calculation
library(SentimentAnalysis)

sentiments = analyzeSentiment(iconv(as.character(keywords$text), to='UTF-8'))
head(sentiments)

#Lexicoder
library(quanteda)
tokenized=quanteda::tokens_lookup(quanteda::tokens(keywords$text), dictionary=data_dictionary_LSD2015, exclusive=FALSE)
sentiments$LCpos = sapply(tokenized, function(x) sum(x=='POSITIVE') - sum(x=='NEG_POSITIVE') + sum(x=='NEG_NEGATIVE'))
sentiments$LCneg = sapply(tokenized, function(x) sum(x=='NEGATIVE') - sum(x=='NEG_NEGATIVE') + sum(x=='NEG_POSITIVE'))
sentiments$LC = (sentiments$LCpos-sentiments$LCneg)/sentiments$WordCount

#Vader
#install.packages('vader')
library(vader)
vader_scores = vader_df(keywords$text)
sentiments$Vader = vader_scores$compound

#Compare dictionaries
#install.packages('GGally')
library(GGally)
with(sentiments, ggpairs(data.frame(SentimentGI, SentimentHE, SentimentLM, 
                                    SentimentQDAP, LC, Vader)))

```

The second installment will be merged into one json file
```{r, echo = FALSE}
keywords2 <- parse_stream("tweet2")
keywords3 <- parse_stream("tweet3")
keywords4 <- parse_stream("tweet4")
tweet_2 <- rbind(keywords2,keywords3,keywords4)

```


```{r, include=TRUE}
tweet_2$text <- gsub("http.*", "", tweet_2$text)
tweet_2$text <- gsub("https.*", "", tweet_2$text)
tweet_2$text <- gsub("&amp;", "&", tweet_2$text)
tweet_2$text <- gsub("RT", "", tweet_2$text)
tweet_2$text <- gsub("6", "six", tweet_2$text)

keywords_clean <- tweet_2 %>%
  select(text) %>%
  unnest_tokens(word, text)
nrow(keywords_clean)

stopwds <- get_stopwords("en")
keywords_cleaner <- keywords_clean %>%
  anti_join(stopwds)
nrow(keywords_cleaner)

plot3 <- keywords_cleaner %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() +
  geom_col(aes(x = word, y = n)) +
  coord_flip() 
plot3
```

```{r, include=TRUE}
library(quanteda)
library(lexicon)

keywords_clean1 <- as.data.frame(keywords_clean)
toks <-  corpus(keywords_clean1$word) %>%
  tokens(remove_punct = TRUE, remove_numbers = FALSE, remove_symbols = TRUE) %>% 
  tokens_wordstem()

toks1 <- data.frame(text = sapply(toks, as.character), stringsAsFactors = FALSE)
plot4 <- toks1 %>%  mutate(word=text) %>%
  anti_join(stopwds) %>%
  count(word, sort = TRUE) %>%
  top_n(15) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot() +
  geom_col(aes(x = word, y = n)) +
  coord_flip()
plot4
```
Comparing all four top 15 words
```{r, include=TRUE}
plot1 + plot2 + plot3 +plot4
```

## Results

This section presents the main results.

### Data exploration

The results section may have a data exploration part, but in general the structure here depends on the specific project.

```{r}
# What happens here depends on the specific project
```

```{r}
# What happens here depends on the specific project
```

### Analysis

This section presents the main results, such as (for example) stats and graphs that show relationships, model results and/or clustering, PCA, etc.

```{r}
# What happens here depends on the specific project
```

```{r}
# What happens here depends on the specific project
```

```{r}
# What happens here depends on the specific project
```

## Discussion

This section summarizes the results and may briefly outline advantages and limitations of the work presented.
